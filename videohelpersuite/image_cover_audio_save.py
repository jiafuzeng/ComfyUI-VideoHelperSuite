import time
import os
import ffmpeg
import subprocess
import math

#You can use this node to save full size images through the websocket, the
#images will be sent in exactly the same format as the image previews: as
#binary images on the websocket with a 8 byte header indicating the type
#of binary message (first 4 bytes) and the image format (next 4 bytes).

#Note that no metadata will be put in the images saved with this node.

class SaveCoverAudioVideo:
    @classmethod
    def INPUT_TYPES(s):
        return {"required":
                    {
                        "filenames": ("VHS_FILENAMES",),
                        "filename_prefix": ("STRING", {"default": "ComfyUI"}),
                        "cover_frame_num":("INT",{"default":1}),
                        "audio_start_s":("INT",{"default":0}),
                        "audio_path": ("STRING", {"default":""}),
                        "cover_img_path": ("STRING", {"default":""}),
                     },
                }

    #RETURN_TYPES = ()
    RETURN_TYPES = ("VHS_FILENAMES",)
    RETURN_NAMES = ("Filenames",)
    FUNCTION = "save_video"
    OUTPUT_NODE = True
    #CATEGORY = "yxkj"
    CATEGORY = "Video Helper Suite ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"

    def replace_first_frame_with_image(self,input_video, input_image,cover_frame_num=1,filename_prefix="comfyui"):
        try:
            # Generate a unique output path
            dir, file_name = os.path.split(input_video)
            timestamp = time.time()
            filename = f"{filename_prefix}_cover_{timestamp}_{file_name}" 
            output_path = os.path.join(dir,filename)

            # Read video and image
            video = ffmpeg.input(input_video)
            image = ffmpeg.input(input_image)

            # Get video metadata
            probe = ffmpeg.probe(input_video)
            video_info = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)
            fps = float(video_info['r_frame_rate'].split('/')[0]) / float(video_info['r_frame_rate'].split('/')[1])

            # Set image duration to 1 frame
            image_duration = cover_frame_num / fps

            # Scale image to match video resolution
            # Scale image to match video resolution and set SAR
            image = image.filter('scale', video_info['width'], video_info['height']).filter('setsar', '1/1')

            # Trim image to 1 frame and adjust timestamps
            image = image.filter('trim', duration=image_duration).filter('setpts', 'PTS-STARTPTS')

            # Extract audio from the original video (if exists)
            audio = video.audio
            # æ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘
            streams = probe.get('stream',[])
            has_audio = any(stream.get('codec_type','') == 'audio' for stream in streams)

            # Trim video to remove the first frame and adjust timestamps
            video = video.filter('trim', start=image_duration).filter('setpts', 'PTS-STARTPTS')

            # Concatenate image and video
            combined_video = ffmpeg.concat(image, video, v=1, a=0)

            # Merge video and audio (if audio exists)
            if has_audio:
                output = ffmpeg.output(combined_video, audio, output_path,vsync="2")
            else:
               output = ffmpeg.output(combined_video, output_path,vsync="2")

            # Run ffmpeg command
            output.run(overwrite_output=True)

            return output_path,filename
        except subprocess.CalledProcessError as e:
            print(f"handle_fisson,æ‰§è¡Œ ffmpeg å‘½ä»¤å¤±è´¥: {e}")
        except FileNotFoundError:
            print("handle_fisson,æœªæ‰¾åˆ° ffmpeg,è¯·ç¡®ä¿å·²å®‰è£… ffmpeg å¹¶æ·»åŠ åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­.")

    def mix_audio_with_video(self,video_path, audio_path, filename_prefix, audio_volume=0.5, audio_start_s=0, original_audio_volume=0.5):
        try:
            timestamp = time.time()
            dir_path, file_name = os.path.split(video_path)
            filename = f"{filename_prefix}_audio_{timestamp}_{file_name}"
            output_path = os.path.join(dir_path, filename)

            # è·å–è§†é¢‘æ—¶é•¿
            video_info = ffmpeg.probe(video_path)
            video_duration = float(video_info['format']['duration'])

            # è·å–å¤–éƒ¨éŸ³é¢‘æ—¶é•¿å’Œé‡‡æ ·ç‡
            audio_info = ffmpeg.probe(audio_path)
            audio_duration = float(audio_info['format']['duration'])

            # è·å–éŸ³é¢‘é‡‡æ ·ç‡
            sample_rate = None
            for stream in audio_info['streams']:
                if stream['codec_type'] == 'audio':
                    sample_rate = int(stream['sample_rate'])
                    break

            if not sample_rate:
                print(f"è·å–å¤–éƒ¨éŸ³é¢‘é‡‡æ ·ç‡å¤±è´¥,ä¸æ·»åŠ å¤–éƒ¨éŸ³é¢‘")
                return video_path, file_name

            # å¦‚æœéŸ³é¢‘èµ·å§‹æ—¶é—´è¶…å‡ºéŸ³é¢‘æ—¶é•¿ï¼Œåˆ™ç›´æ¥è¿”å›åŸè§†é¢‘è·¯å¾„
            if audio_start_s >= audio_duration:
                print(f"éŸ³é¢‘èµ·å§‹æ—¶é—´ {audio_start_s}s è¶…è¿‡éŸ³é¢‘æ—¶é•¿ {audio_duration}s,ä¸æ·»åŠ å¤–éƒ¨éŸ³é¢‘")
                return video_path, file_name

            # åŠ è½½è¾“å…¥æµ
            video_input = ffmpeg.input(video_path)
            audio_input = ffmpeg.input(audio_path)

            # å¤„ç†å¤–éƒ¨éŸ³é¢‘ï¼ˆè°ƒæ•´éŸ³é‡å¹¶è£å‰ªèµ·å§‹æ—¶é—´ï¼‰
            adjusted_audio = (
                audio_input.audio
                .filter('atrim', start=audio_start_s)
                .filter('asetpts', 'PTS-STARTPTS')  # é‡æ–°å¯¹é½æ—¶é—´è½´
                .filter('volume', volume=audio_volume)
            )

            # è®¡ç®—å¤–éƒ¨éŸ³é¢‘å¯ç”¨æ—¶é•¿
            remaining_audio_duration = max(audio_duration - audio_start_s, 0)

            # å¦‚æœå¤–éƒ¨éŸ³é¢‘æ—¶é•¿çŸ­äºè§†é¢‘æ—¶é•¿ï¼Œåˆ™è¿›è¡Œå¾ªç¯
            if remaining_audio_duration < video_duration:
                loops = math.ceil(video_duration / remaining_audio_duration)
                adjusted_audio = adjusted_audio.filter('aloop', loop=loops, size=int(video_duration * sample_rate))

            # è£å‰ªåˆ°è§†é¢‘æ—¶é•¿
            adjusted_audio = adjusted_audio.filter('atrim', duration=video_duration)

            # å¤„ç†è§†é¢‘åŸå§‹éŸ³é¢‘
            video_audio = None
            for stream in video_info['streams']:
                if stream['codec_type'] == 'audio':
                    video_audio = (
                        video_input.audio
                        .filter('volume', original_audio_volume)
                        .filter('atrim', duration=video_duration)
                    )
                    break  

            # æ··åˆéŸ³é¢‘
            if adjusted_audio and video_audio:
                mixed_audio = ffmpeg.filter([video_audio, adjusted_audio], 'amix', inputs=2)
            else:
                mixed_audio = adjusted_audio if adjusted_audio else video_audio

            # è¾“å‡ºé…ç½®
            output = ffmpeg.output(
                video_input.video,
                mixed_audio,
                output_path,
                vcodec='copy',
                acodec='aac',
                strict='experimental'
            )

            output.run(overwrite_output=True)
            return output_path, filename

        except ffmpeg.Error as e:
            print(f"FFmpeg é”™è¯¯: {e.stderr.decode('utf-8')}")
        except KeyError as e:
            print(f"å…ƒæ•°æ®é”™è¯¯: ç¼ºå°‘å¿…è¦å­—æ®µ {e}")
        except Exception as e:
            print(f"æœªçŸ¥é”™è¯¯: {str(e)}")

    def save_video(self,filenames,filename_prefix:str,audio_path:str,cover_img_path:str,cover_frame_num:int,audio_start_s:int):
        video_path = filenames[1][-1]
        if len(cover_img_path) > 1:
            cover_video,cover_file_name = self.replace_first_frame_with_image(video_path,cover_img_path,cover_frame_num,filename_prefix)
        else:
            cover_video = video_path

        if len(audio_path) > 1:
            cover_audio_video,cover_audio_file_name = self.mix_audio_with_video(cover_video,audio_path,filename_prefix, audio_volume=0.5, audio_start_s=0, original_audio_volume=0.5)
        else:
            cover_audio_video = cover_video
            cover_audio_file_name = os.path.split(cover_audio_video)[-1]

        preview = {
            "filename": cover_audio_file_name,
            "subfolder": "",
            "type": "output",
            "format": "video/h264-mp4",
            #"frame_rate": frame_rate,
            #"workflow": first_image_file,
            "fullpath": cover_audio_video,
        }
        return {"ui":{"gifs": [preview]},"result": ((cover_audio_video, cover_audio_file_name),)}

    @classmethod
    def IS_CHANGED(s, filenames):
        return filenames

#NODE_CLASS_MAPPINGS = {
#    "SaveCoverAudioVideo":SaveCoverAudioVideo,
#}
